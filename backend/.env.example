# Server Configuration
PORT=3000
NODE_ENV=development

# AI Provider Configuration (choose one or multiple)
# OpenAI (Recommended for best function calling and reliability)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Anthropic
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Groq (FREE - but function calling limited)
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# Ollama (local - FREE)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Default AI Provider (openai, anthropic, groq, or ollama)
AI_PROVIDER=openai

# GitHub Integration
GITHUB_TOKEN=your_github_personal_access_token

# Docker Configuration (optional, defaults to local Docker daemon)
DOCKER_HOST=unix:///var/run/docker.sock
# DOCKER_HOST=tcp://localhost:2375  # For Windows/remote Docker

# Kubernetes Configuration (optional, defaults to ~/.kube/config)
KUBECONFIG=~/.kube/config

# CI/CD Integration (optional)
JENKINS_URL=
JENKINS_USER=
JENKINS_TOKEN=

GITLAB_URL=
GITLAB_TOKEN=

# Logging
LOG_LEVEL=info
